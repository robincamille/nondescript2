<!DOCTYPE html>
<html lang="en">
<head>
<link rel= "stylesheet" type= "text/css" href= "{{ url_for('static',filename='style.css') }}">

<title>NONDESCRIPT</title>
<link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700,600' rel='stylesheet' type='text/css'>
</head>
<body style="background:MediumTurquoise;line-height: 1.5em">

    <h1><a href="/" style="color:#fff;border:0;">NONDESCRIPT</a></h1>
    <div style="background:#fff"><br/>
    <h2>About</h2>
    <p style="margin-bottom:0">
	Nondescript is a web tool designed to aid a user in revising their message until it is sufficiently anonymized, relevant to their provided writing sample and a randomly changing background corpus of web writing. Nondescript is designed to be publicly available on the web, as is the code behind it.
</p>
<p>See the full writeup:<br/>
Davis, Robin Camille (2016). <a href="http://academicworks.cuny.edu/gc_etds/1343/">Nondescript: A Web Tool to Aid Subversion of Authorship Attribution</a> (master's thesis). Graduate Center, City University of New York, New York.</p>

    <h2 >Brief writeup</h2>
<p style="margin-bottom:0">The user inputs a writing sample of at least 7,000 words in the left field. On the right, the user inputs the message they want to anonymize. Once the user clicks "Submit," the features of the sample and message are analyzed in relation to each other and to the background corpus. 

</p><p style="margin-bottom:0">The background corpus is exchangeable but should include at least 20 documents, each written by a different author and consisting of at least 50,000 words. No background corpus is included with this code. For the purposes of this project, I used a subset of the <a href="http://u.cs.biu.ac.il/~koppel/BlogCorpus.htm">Blog Authorship Corpus</a> (Schler, Koppel, Argamon, & Pennebaker, 2006). This corpus comprises a large web crawl of Blogger.com blogs collected in August 2004. The blogs are unformatted plain text, with the exception of date and post XML tags and the token "urllink" to denote a location where a link used to be. Within this corpus, there are a wide range of topics and writing styles, from technical discussions about computer programming to intensely personal narratives. The only issue encountered in using this corpus was that it dates from 2004, so neologisms created since then would not be in that data set, and topics touching on then-current events may be quite dated. However, only the top 1,000 most frequent words are considered, leaving most context-bound words out of the equation.  
</p><p style="margin-bottom:0">First, three cosine similarity scores are calculated, based on the top 100, 1,000, and 10,000 most frequent words in the background corpus (tf-idf vectors). Highly similar messages will score in the 0.8 to 0.9 range. Dissimilar messages may score 0.4 to 0.6. 
</p><p style="margin-bottom:0">Next, a Naive Bayes classifier is trained and used for prediction. Seven other authors from the background corpus are randomly selected; four non-consecutive, 7,000-word chunks of each author's writing are set aside, two for training and two for testing. All documents are converted to arrays of term frequencies for the vocabulary of 1,000 words. This vocabulary of the 1,000 most frequently used words (unstemmed) in the background corpus is a deliberately small vocabulary, chosen so that the classifier might strike a balance between being too naive and too influenced by the genre of writing. Relying only on function words can result in somewhat accurate classifiers, but this is too limiting. Allowing all words encountered to enter the vocabulary means the classifier is too subject to topic rather than style. That may be acceptable in some classification situations, but for a general-use web tool, neutralizing genre makes the tool more usable. The vocabulary is included in the code for Nondescript.
</p><p style="margin-bottom:0">The classifier is trained on the sample and the 14 other documents, then is used to predict the author of the message and of the other 14 documents. Because all authors are in fact known, a classifier score can be provided (e.g., 0.83 or 83% accurate). The user likely only cares that their document is anonymized, so a simple sentence toggle displays on the output screen, either "Message is still attributed to you by this classifier" or "Message successfully anonymized for this classifier." Term frequency array conversion and classification are both done using the Sci-kit Learn Python library (Pedregosa et al., 2011).
</p><p style="margin-bottom:0">For the next step, the user's writing style undergoes a simple stylometric analysis: How does their message's average word length compare to their sample's average word length? What about average sentence length? How do those two measures compare to the background corpus, overall? These numbers are achieved by a simple mean and presented as a percentage, e.g., "Your sentences are 1.98x longer than average, compared to the background corpus." Furthermore, term frequencies are compared between the user's submissions and the rest of the background corpus. The 5 most unusually frequent words are displayed, e.g., "'after' is 6.46x more frequent (used 12 times)." These statistics only display for words used at least twice. 
</p><p style="margin-bottom:0">Lastly, because Nondescript is designed to be used iteratively, the page includes editable text fields so the user can revise their message. Revision happens in the tabbed text box in the bottom half of the page. Because this classifier (like many) relies on word frequencies to attribute authorship, the user is encouraged to find different words to express their message. Synonyms for some words are found through WordNet (available through NLTK), and these synonym suggestions are included parenthetically, e.g., "MUCH (a lot, lots, very much, practically)." This appears in the first tab, entitled "Revise manually." The second tab, titled "I'm feeling fortuitous," chooses synonyms at random for some words. Part of speech, tense, number, tone, and other more complex nuances of language are not considered here. As a result, these synonyms may make sense (e.g., "immediately" replacing "directly") or may fall prey to WordNet's wide-net collection of synonyms, resulting in interesting but unhelpful word replacement (e.g., "ternary" replacing "three"). For these first two tabs, word replacement is filtered using the WordFilter Python library and an additional set of words to avoid offensive language (Kazemi, 2016). The final tab, "Message as submitted," is merely a copy of the message the user submitted. The text output in all three tabs is editable, and the user may revise and submit in the text field of their choice to see if their scores improve â€”mdash; that is, Nondescript re-analyzes and re-classifies the revised message (the original writing sample remains the same). The output will appear the same window, with new metrics, having undergone another round of classification with other randomly chosen authors. 
</p><p style="margin-bottom:0">Behind the web form interface, Python scripts are handling the classification tasks within the Flask framework. Data is passed to and from the web form through Flask. A classifier file, created by the Sci-kit Learn library, is saved in the same directory as the scripts.
</p><p style="margin-bottom:0"><strong>Caveat</strong>:	In no way does Nondescript guarantee that a user's message will be truly anonymized. Even if a message deceives the classifier, it may only be "anonymous" within the context of the seven other writers randomly chosen in that instance. Submitting the same exact message may result in different scores, as the random background corpus could make classification easier or harder purely by chance. 

    </p>
</div>

    <p>This data is not stored. Make sure you have your own copy. Information about users is not stored by Nondescript.</p>
</body>
</html>
